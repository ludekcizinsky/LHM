{
  "os": "Linux-5.14.0-70.30.1.el9_0.x86_64-x86_64-with-glibc2.34",
  "python": "CPython 3.10.19",
  "startedAt": "2025-11-29T16:35:50.635617Z",
  "args": [
    "--output_dir=/scratch/izar/cizinsky/thesis/preprocessing/taichi/lhm",
    "--scene_name=taichi",
    "--epochs=10",
    "--batch_size=5",
    "--exp_name=dev"
  ],
  "program": "/home/cizinsky/LHM/LHM/finetune_multi_humans.py",
  "codePath": "LHM/finetune_multi_humans.py",
  "codePathLocal": "LHM/finetune_multi_humans.py",
  "git": {
    "remote": "git@github.com:ludekcizinsky/LHM.git",
    "commit": "285d9a37a4457e7c3d56d1855f18e1b26a2b4839"
  },
  "email": "ludekcizinsky11@gmail.com",
  "root": "/home/cizinsky/LHM",
  "host": "i30",
  "executable": "/scratch/izar/cizinsky/venvs/lhm/bin/python",
  "cpu_count": 40,
  "cpu_count_logical": 40,
  "gpu": "Tesla V100-PCIE-32GB",
  "gpu_count": 1,
  "disk": {
    "/": {
      "total": "53660876800",
      "used": "8406462464"
    }
  },
  "memory": {
    "total": "201910206464"
  },
  "gpu_nvidia": [
    {
      "name": "Tesla V100-PCIE-32GB",
      "memoryTotal": "34359738368",
      "cudaCores": 5120,
      "architecture": "Volta",
      "uuid": "GPU-0c983f73-3e90-2236-71bf-769ecd5f5968"
    }
  ],
  "cudaVersion": "12.2",
  "slurm": {
    "job_id": "2737298"
  },
  "writerId": "m96a9anj0ucvqw7r4d1hykhdg36lhcmn"
}